{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from nlpclass.config import model_config\n",
    "from nlpclass.data.data_utils import TranslationDataset, text_collate_func\n",
    "from nlpclass.models.evaluation_utils import bleu_eval, output_to_translations\n",
    "from nlpclass.models.models import DecoderRNN, EncoderRNN, TranslationModel\n",
    "from nlpclass.models.training_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_DIR = osp.join(CURRENT_PATH, '..', 'data')\n",
    "MODEL_DIR = osp.join(CURRENT_PATH, '..','models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "Counted words:\n",
      "eng 35151\n",
      "vi 43279\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3562\n",
      "vi 3678\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3361\n",
      "vi 3518\n"
     ]
    }
   ],
   "source": [
    "data, data_loaders, max_length = load_data('vi', batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=300,\n",
    "    hidden_size=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    pretrained_embeddings=data['train'].input_lang.embeddings,\n",
    "    bidirectional=True).to(model_config.device)\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=300,\n",
    "    hidden_size=128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    pretrained_embeddings=data['train'].output_lang.embeddings,\n",
    "    attention=True).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=1.0).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, target, criterion):\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    target_flat = target.view(-1, 1).squeeze()\n",
    "    return criterion(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9166be693e415984c4306fbc89779b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6251, device='cuda:0')\n",
      "0.5936727299251386\n",
      "tensor(3.3127, device='cuda:0')\n",
      "1.6027140964129813\n",
      "tensor(2.8484, device='cuda:0')\n",
      "2.292629685459052\n",
      "tensor(2.2910, device='cuda:0')\n",
      "4.914684249301489\n",
      "tensor(1.9952, device='cuda:0')\n",
      "5.262287046642645\n",
      "tensor(1.5924, device='cuda:0')\n",
      "7.016682515114114\n",
      "tensor(1.5501, device='cuda:0')\n",
      "8.582478523753394\n",
      "tensor(1.2819, device='cuda:0')\n",
      "8.681783192243731\n",
      "tensor(1.3297, device='cuda:0')\n",
      "9.556247002276868\n",
      "tensor(1.3010, device='cuda:0')\n",
      "9.568101622144765\n",
      "tensor(1.3031, device='cuda:0')\n",
      "10.58796197851855\n",
      "tensor(0.9066, device='cuda:0')\n",
      "11.174392798479518\n",
      "tensor(1.0672, device='cuda:0')\n",
      "12.892230064192653\n",
      "tensor(1.1184, device='cuda:0')\n",
      "12.717057652800923\n",
      "tensor(0.8126, device='cuda:0')\n",
      "13.374455763125784\n",
      "tensor(1.1716, device='cuda:0')\n",
      "12.64711309856782\n",
      "tensor(0.8032, device='cuda:0')\n",
      "12.901827172145309\n",
      "tensor(0.8611, device='cuda:0')\n",
      "13.684486609129518\n",
      "tensor(0.9717, device='cuda:0')\n",
      "12.75010872298263\n",
      "tensor(0.8819, device='cuda:0')\n",
      "11.689790956338824\n",
      "tensor(0.9481, device='cuda:0')\n",
      "12.864672726394177\n",
      "tensor(0.9895, device='cuda:0')\n",
      "13.408951748308496\n",
      "tensor(0.8650, device='cuda:0')\n",
      "14.375996806142444\n",
      "tensor(0.9063, device='cuda:0')\n",
      "14.272793476258757\n",
      "tensor(0.8774, device='cuda:0')\n",
      "13.929017051825785\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(25)):\n",
    "    for batch in data_loaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        logits = translation_model(batch)\n",
    "        loss = calc_loss(logits, batch['target'], criterion)\n",
    "        loss.backward()\n",
    "        translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "        translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "        clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                                   translation_model.parameters()), model_config.grad_norm)\n",
    "        optimizer.step() \n",
    "    original, translation = evaluate(translation_model, data, data_loaders, dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "input_seq = x['input']\n",
    "target_seq = x['target']\n",
    "input_length = x['input_length']\n",
    "target_length = x['target_length']\n",
    "\n",
    "encoded_input, hidden = translation_model.encoder.forward(input_seq, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(10.2678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.5081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.9124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0610, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3755, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-2)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(x)\n",
    "    loss = calc_loss(logits, x['target'], criterion)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.greedy(x), data['train'])\n",
    "bleu_eval(original, translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, data_loaders, dataset_type='dev', max_batches=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        original_strings = []\n",
    "        translated_strings = []\n",
    "        for i, batch in enumerate(data_loaders[dataset_type]):\n",
    "            if i > max_batches:\n",
    "                break\n",
    "            logits = translation_model(batch)\n",
    "            epoch_loss = calc_loss(logits, batch['target'], criterion)\n",
    "            original = output_to_translations(batch['target'], data['train'])\n",
    "            translations = output_to_translations(model.greedy(batch), data['train'])\n",
    "            original_strings.extend(original)\n",
    "            translated_strings.extend(translations)\n",
    "        bleu = bleu_eval(original_strings, translated_strings)\n",
    "        model.train()\n",
    "        print(epoch_loss)\n",
    "        print(bleu)\n",
    "        \n",
    "        return original_strings, translated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)\n",
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae579e94158f443cbb05f59850a6cb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8333), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.6677, device='cuda:0')\n",
      "3.58132009002981e-05\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm_notebook(data_loaders['train'])):\n",
    "    if i % 500 == 0:\n",
    "        evaluate(translation_model, data, data_loaders)\n",
    "        #evaluate(translation_model, data, data_loaders, dataset_type='train')\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(batch)\n",
    "    loss = calc_loss(logits, batch['target'], criterion)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strings, translated_strings = evaluate(translation_model, data, data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball be later but of volumes all. hope. answer. only were',\n",
       " 'be this. 65. know what must truth. i most',\n",
       " 'games be practical everybody pins your needles all forward careful were',\n",
       " 'i moment. it attack. be sorrows. ten.',\n",
       " 'canadian be appointment careful laugh. no truth. something time were',\n",
       " 'beautiful cupboard. hot. wine these',\n",
       " 'much. but how bitter really dishonesty fed recently',\n",
       " 'applied all else fed to climate husbands. matter. key',\n",
       " 'but they answer. perfect. today. tape',\n",
       " 'i is invented i situation getting powers your few']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = translation_model.greedy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in predictions.cpu().numpy():\n",
    "    decoded_words = []\n",
    "    for elem in row[1:]:\n",
    "        decoded_words.append(data['train']['output_lang'].index2word[elem])\n",
    "        if elem == model_config.EOS_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = Variable(torch.LongTensor([model_config.SOS_token] * 8)).to(model_config.device)\n",
    "yo = torch.stack((yo, topi.squeeze(), topi.squeeze()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = torch.autograd.Variable(torch.LongTensor(np.repeat([2], len(x['input_length'])))).to(model_config.device)\n",
    "mask = seq_range < x['input_length']\n",
    "loss = -torch.gather(decoder_output, dim=1, index=input_var.unsqueeze(1)).squeeze() * mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4193, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum() / torch.sum(loss > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(loss > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(x['input'], x['input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = None\n",
    "if decoder.attention:\n",
    "    context = Variable(torch.zeros(encoder_output.size(0), encoder_output.size(2))).unsqueeze(1).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, context, weights = decoder(input_var, encoder_hidden, encoder_output, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item() * \\\n",
    "            len(batch['label']) / len(train_loader.dataset)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30a2084915f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-df8527ea006d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(translation_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(translation_model, optimizer, train_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
