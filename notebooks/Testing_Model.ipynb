{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from nlpclass.config import model_config\n",
    "from nlpclass.data.data_utils import TranslationDataset, text_collate_func\n",
    "from nlpclass.models.evaluation_utils import bleu_eval, output_to_translations\n",
    "from nlpclass.models.models import DecoderRNN, EncoderCNN, EncoderRNN, TranslationModel\n",
    "from nlpclass.models.training_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_DIR = osp.join(CURRENT_PATH, '..', 'data')\n",
    "MODEL_DIR = osp.join(CURRENT_PATH, '..','models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "Counted words:\n",
      "eng 6726\n",
      "vi 7801\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3562\n",
      "vi 3678\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3361\n",
      "vi 3518\n"
     ]
    }
   ],
   "source": [
    "data, data_loaders, max_length = load_data('vi', batch_size=24, subsample=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderCNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2).to(model_config.device)\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=False).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True).to(model_config.device)\n",
    "if encoder.bidirectional:\n",
    "    multiplier = 2\n",
    "else:\n",
    "    multiplier = 1\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=multiplier * 128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=True).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, target, criterion):\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    target_flat = target.view(-1, 1).squeeze()\n",
    "    return criterion(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, data_loaders, dataset_type='dev', max_batches=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        original_strings = []\n",
    "        translated_strings = []\n",
    "        for i, batch in enumerate(data_loaders[dataset_type]):\n",
    "            if i > max_batches:\n",
    "                break\n",
    "            logits = translation_model(batch)\n",
    "            epoch_loss = calc_loss(logits, batch['target'], criterion)\n",
    "            original = output_to_translations(batch['target'], data['train'])\n",
    "            translations = output_to_translations(model.greedy(batch), data['train'])\n",
    "            original_strings.extend(original)\n",
    "            translated_strings.extend(translations)\n",
    "        bleu = bleu_eval(original_strings, translated_strings)\n",
    "        model.train()\n",
    "        print(epoch_loss)\n",
    "        print(bleu)\n",
    "        \n",
    "        return original_strings, translated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f60ae989f624577acc252dfc2ff72ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20687949540555664 0.743069744848148 4.013472080230713\n",
      "0.12416938919414126 0.6604997387830878 3.7681403160095215\n",
      "0.13508697794634295 0.6325013233520471 3.702760934829712\n",
      "0.15965794342790685 0.7780846420221936 3.3308780193328857\n",
      "0.13891497467307007 0.6817508205555265 3.623516082763672\n",
      "0.18881076632940158 0.6468502333631365 3.6622562408447266\n",
      "0.14682974048378822 0.789686836431067 3.581509590148926\n",
      "0.1722922481946444 0.879440958576494 3.5672218799591064\n",
      "0.1414990225701052 0.8122170260704333 4.425287246704102\n",
      "0.12318427220892757 0.6475319841955293 3.660111904144287\n",
      "0.24132099098312035 0.9584002422650365 4.579545021057129\n",
      "2.613765115920316 2.7143743025408686 3.156601905822754\n",
      "0.14568374672073903 0.725659107231157 4.8209638595581055\n",
      "0.15574742905080718 0.7884909870215104 4.6951069831848145\n",
      "0.15614441856176567 0.7117643127225174 4.787650108337402\n",
      "0.2310522976092384 0.9225341664906159 3.594244956970215\n",
      "0.23398980242293765 0.7732889899855478 4.674855709075928\n",
      "0.2120586559093853 0.9873475229225002 4.527430057525635\n",
      "0.17151034104950807 0.8770485076275041 4.524731636047363\n",
      "0.40133185463419274 0.8781563872125686 3.8359923362731934\n",
      "0.1831937808200951 0.5643196200707961 4.907942295074463\n",
      "0.16890477082402938 0.7448569094212427 4.728829383850098\n",
      "0.17165261905008222 0.7277068284030936 3.7062039375305176\n",
      "0.16366048742435943 0.8452652670694635 4.787906169891357\n",
      "0.2241932792209237 0.920310548981043 3.553723096847534\n",
      "0.17733083569505653 0.6951082430026714 4.902565002441406\n",
      "0.15002175359644743 0.8430997301380617 4.476989269256592\n",
      "0.15936077687080466 0.8394637296841878 4.658317565917969\n",
      "0.24685064153092004 0.754792090997269 4.704642295837402\n",
      "0.19534935128803768 0.7971090216815746 4.720793724060059\n",
      "0.1666076177199404 0.8141373508548616 4.461499214172363\n",
      "0.1401728417835798 0.689117524039588 3.85225772857666\n",
      "0.2748740280939074 1.1925243238543046 3.657109022140503\n",
      "0.15827818937494417 0.9590940276500588 4.613011837005615\n",
      "0.25926805103864553 0.7784785924849382 4.847214221954346\n",
      "0.4474439680919689 1.1220711188384793 4.532372951507568\n",
      "0.1745688633732639 0.5843159755868874 3.9799721240997314\n",
      "0.19300832710329188 0.7872570594496506 4.643325328826904\n",
      "0.21734183335578802 0.8844043772088827 4.785367012023926\n",
      "0.18689898204171748 0.7415862582893423 3.7890663146972656\n",
      "0.21210206641809778 0.8371111302926667 4.627038478851318\n",
      "0.18018350553192697 0.8018444889171501 4.616052150726318\n",
      "0.220597428141577 0.7999180362373455 4.73818302154541\n",
      "0.18424486711182608 0.8190523295680068 4.621437072753906\n",
      "0.16918717498433475 0.7667596195094831 3.5930275917053223\n",
      "0.20289508939984388 0.6824051957996916 4.635509490966797\n",
      "0.1873186282984018 0.8339749847086434 4.3824334144592285\n",
      "0.3209822250211335 1.0140325407190398 4.577015399932861\n",
      "0.17506070920766004 0.6638344406351234 4.74635648727417\n",
      "0.16861984995130477 0.8884102159956407 4.8433051109313965\n",
      "0.1076861309551586 0.634563237094796 3.9488465785980225\n",
      "0.34891053492191787 0.9262809114996348 4.85308313369751\n",
      "0.18225876453306844 0.7818819451305958 4.861710548400879\n",
      "0.1448205442853363 0.6685489869887296 4.807345390319824\n",
      "0.11888454657155868 0.7067833137610166 3.5533742904663086\n",
      "0.12649963448536225 0.6371380949518242 3.9784719944000244\n",
      "0.13588113234798246 0.621884506256253 4.8687028884887695\n",
      "0.16120081644481724 0.8285097637221391 4.8406572341918945\n",
      "0.11498038763871118 0.7246744295894987 4.702734470367432\n",
      "0.17088326766208478 0.7269517867574997 4.848508358001709\n",
      "0.20788522217904376 0.8232538625271577 4.618028163909912\n",
      "0.16000506208070256 0.7539072115382067 4.939887046813965\n",
      "0.18497681938948637 0.7774291532483378 4.969141483306885\n",
      "0.1874035180970935 0.8852114884132884 3.5922601222991943\n",
      "0.1879918625874233 0.735993451614074 4.600271224975586\n",
      "0.1999087613449453 0.9625408787633416 4.3291120529174805\n",
      "0.18563283828638721 0.8687933902293467 4.735717296600342\n",
      "0.13323980843344085 0.6959871313692324 3.9285385608673096\n",
      "0.39212366642619895 1.0439918570542066 4.831244468688965\n",
      "0.14112933061685992 0.7223348790092508 3.91632342338562\n",
      "0.17226597963858886 0.6794765420842953 3.9140255451202393\n",
      "0.1952817381661457 0.6675615766856485 3.893653154373169\n",
      "0.13469001753072474 0.941821250596899 4.582585334777832\n",
      "0.37098872955669093 1.0846460791374213 3.6985535621643066\n",
      "0.13536345828994414 0.6942344886706896 3.8529932498931885\n",
      "0.1688725826236619 0.8137873498325005 3.6292195320129395\n",
      "0.27734294086374267 0.808186291369607 3.794173240661621\n",
      "0.318126835147505 0.9995417194145442 4.691483974456787\n",
      "0.18487898874614542 0.6972551098804665 3.874690055847168\n",
      "0.17135018601039942 0.7173284237005759 3.833508014678955\n",
      "0.1433850763535038 0.664815271325096 4.094608783721924\n",
      "0.1660331164310593 0.9309736383100258 4.653637409210205\n",
      "0.26734254253533724 1.0528305342582964 4.493492126464844\n",
      "0.24017368060424713 0.8402070922794991 4.842807292938232\n",
      "0.19545891888602288 0.6742098720052796 4.958073139190674\n",
      "0.19798871446456207 0.7789647899941865 4.949044227600098\n",
      "0.23146887923335527 0.8996454962773957 4.601970672607422\n",
      "0.20815688018917075 0.8370434678149877 3.814103603363037\n",
      "0.1493645189136655 0.939749805916884 3.761638879776001\n",
      "0.1801019808766795 0.7766249539539006 4.799112796783447\n",
      "0.18219532770988717 0.7534358157478933 3.917670965194702\n",
      "0.15351092879388284 0.7310518630440072 4.826419353485107\n",
      "0.14967664588478488 0.7511230960076042 3.8670804500579834\n",
      "0.2157584391269232 0.7364612993142281 4.9014892578125\n",
      "0.19030043248144035 0.7951787765483626 4.678738594055176\n",
      "0.21667295912954398 0.8515968939268642 4.754951477050781\n",
      "0.24511949623989152 0.8817686814336536 5.04965353012085\n",
      "0.14891180428691306 0.7396404456504465 4.095920085906982\n",
      "0.13406090587289476 0.647516424016194 3.8874659538269043\n",
      "0.22651653457545404 0.8691991372616908 3.723670721054077\n",
      "0.13407464870470606 0.776098936582249 3.9083127975463867\n",
      "0.19804637634639272 0.7459877303228538 3.7865583896636963\n",
      "0.225135402290781 0.766418428552493 4.72047758102417\n",
      "0.2375748324539988 0.7783720243473865 4.899893283843994\n",
      "0.23964588887494725 0.8741200932370546 3.8037595748901367\n",
      "0.13184025156836499 0.6462958373101668 4.810610771179199\n",
      "0.17511253003378713 0.634902874541776 5.000087261199951\n",
      "0.699078110387474 1.5988934385508802 3.9728901386260986\n",
      "0.20158180560809857 0.692374752760745 3.973938465118408\n",
      "0.1898987630669287 0.8215412868851976 4.7684478759765625\n",
      "0.24204587559496193 0.9703893959281874 3.675772190093994\n",
      "0.2393248345994944 0.8954290124501633 4.74472188949585\n",
      "0.17712349532920443 0.7347087992544236 3.5888352394104004\n",
      "0.2530327436180085 0.9871018271396801 4.448761463165283\n",
      "0.24729937420440434 1.071695552800138 3.339704990386963\n",
      "0.21459236050292751 0.8839639373705873 3.66447114944458\n",
      "0.2578014958239457 0.7286518373860866 4.002328872680664\n",
      "0.29696998282452636 1.0273877966239675 4.7464118003845215\n",
      "0.175068280205887 0.8110314665073418 3.607079267501831\n",
      "0.1726438501140757 0.6964227267113853 3.832179069519043\n",
      "0.2621594703631741 1.0162158284026401 3.667023181915283\n",
      "0.16830612768145262 0.7781127380114019 3.9615299701690674\n",
      "0.21359409495678439 0.9638469534809462 4.70749044418335\n",
      "0.24429416917842992 0.795629619637978 3.694777011871338\n",
      "0.20852654709681084 0.8499175152475084 5.109195232391357\n",
      "0.1868289834885544 0.8022675930853971 3.789475202560425\n",
      "0.27907039181500304 0.8792091279176178 4.637414455413818\n",
      "0.13949987417792814 0.7127183464289206 4.003834247589111\n",
      "0.22926414886922164 0.8743653984433631 3.928056240081787\n",
      "0.1826440415184751 0.8027904287459457 4.95933198928833\n",
      "0.25976769881680833 0.7304050768096118 4.920943260192871\n",
      "0.2132930520244033 0.9068542676831096 3.847715377807617\n",
      "1.9527542141900784 2.8445189471911174 4.916173934936523\n",
      "0.22558034284886277 0.8974084825366345 3.4881784915924072\n",
      "0.22963159159517166 0.8115164497361612 4.9178924560546875\n",
      "0.21155000543715147 0.8377293702608406 4.8382391929626465\n",
      "0.2403481077626424 0.7843803719452795 3.8875906467437744\n",
      "0.3196396066646811 1.1004992844743484 4.489470481872559\n",
      "0.13479036029548283 0.7808508870354214 3.892871379852295\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-3a13dce72b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-173-e54a703a6445>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data, data_loaders, dataset_type, max_batches)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_to_translations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_to_translations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0moriginal_strings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtranslated_strings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             decoder_output, decoder_hidden, context, weights = self.decoder(\n\u001b[0;32m--> 222\u001b[0;31m                 decoder_input, decoder_hidden, encoder_output, context)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_output, context)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             output = F.log_softmax(\n\u001b[0;32m--> 129\u001b[0;31m                 self.out(torch.cat((context.squeeze(1), output.squeeze(1)), 1)), 1)\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(25)):\n",
    "    for batch in data_loaders['train']:\n",
    "        translation_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits = translation_model(batch)\n",
    "        loss = calc_loss(logits, batch['target'], criterion)\n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_norm = 0\n",
    "        for p in translation_model.encoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            encoder_norm += param_norm.item() ** 2\n",
    "        decoder_norm = 0\n",
    "        for p in translation_model.decoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            decoder_norm += param_norm.item() ** 2\n",
    "            \n",
    "        print(encoder_norm, decoder_norm, loss.item())\n",
    "            \n",
    "        clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                                   translation_model.parameters()), 5.0)\n",
    "        \n",
    "        optimizer.step() \n",
    "    original, translation = evaluate(translation_model, data, data_loaders, dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6531460812606793\n",
      "[('in the of that i could be able to you .', 'well in 25 years i was mostly putting out pieces of this romance and not getting a lot back in because design on call doesnt always connect you with a circumstance in which you can produce things of this nature .'), ('these conversations and you and it and and and and and and and and and and and and and tedmed and it and redesign and it and redesign and it and redesign and it and redesign and it and redesign and it .', 'your medical chart its hard to access impossible to read and full of information that could make you healthier if you just knew how to use it . at tedmed thomas goetz looks at medical data making a bold call to redesign it and get more insight from it .'), ('eighteen months in the in the in the in the in the in her congressmen in the united states and the her congressmen her congressmen her congressmen her congressmen in the united states .', 'eighteen months later at the age of 90 she arrived in washington with hundreds following her including many congressmen who had gotten in a car and driven out about a mile outside of the city to walk in with her .')]\n"
     ]
    }
   ],
   "source": [
    "#x = next(iter(data_loaders['train']))\n",
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.greedy(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(list(zip(translations[0:3], original[0:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_model.beam_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.349895955513169\n",
      "[('in in a lot of the of that .', 'well in 25 years i was mostly putting out pieces of this romance and not getting a lot back in because design on call doesnt always connect you with a circumstance in which you can produce things of this nature .'), ('these conversations and to the it and and and and and and and you and it and goetz and tedmed and tedmed and tedmed .', 'your medical chart its hard to access impossible to read and full of information that could make you healthier if you just knew how to use it . at tedmed thomas goetz looks at medical data making a bold call to redesign it and get more insight from it .'), ('eighteen months in in the united states in the united states in the united states in the united states .', 'eighteen months later at the age of 90 she arrived in washington with hundreds following her including many congressmen who had gotten in a car and driven out about a mile outside of the city to walk in with her .')]\n"
     ]
    }
   ],
   "source": [
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.beam_search(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(list(zip(translations[0:3], original[0:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0618, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-2)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(x)\n",
    "    loss = calc_loss(logits, x['target'], criterion)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)\n",
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34410a3c73c44d89f2e6cddd5d165c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1389), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.1450, device='cuda:0')\n",
      "0.0008142795832761162\n",
      "tensor(9.0464, device='cuda:0')\n",
      "0.0033784249080402885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-bf6d2f87ea3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#evaluate(translation_model, data, data_loaders, dataset_type='train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         decoder_outputs = Variable(torch.zeros(\n\u001b[0;32m--> 166\u001b[0;31m             model_config.max_length + 1, batch_size, self.decoder.output_size)).to(model_config.device)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm_notebook(data_loaders['train'])):\n",
    "    if i % 500 == 0:\n",
    "        evaluate(translation_model, data, data_loaders)\n",
    "        #evaluate(translation_model, data, data_loaders, dataset_type='train')\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(batch)\n",
    "    loss = calc_loss(logits, batch['target'], criterion)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strings, translated_strings = evaluate(translation_model, data, data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball be later but of volumes all. hope. answer. only were',\n",
       " 'be this. 65. know what must truth. i most',\n",
       " 'games be practical everybody pins your needles all forward careful were',\n",
       " 'i moment. it attack. be sorrows. ten.',\n",
       " 'canadian be appointment careful laugh. no truth. something time were',\n",
       " 'beautiful cupboard. hot. wine these',\n",
       " 'much. but how bitter really dishonesty fed recently',\n",
       " 'applied all else fed to climate husbands. matter. key',\n",
       " 'but they answer. perfect. today. tape',\n",
       " 'i is invented i situation getting powers your few']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = translation_model.greedy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in predictions.cpu().numpy():\n",
    "    decoded_words = []\n",
    "    for elem in row[1:]:\n",
    "        decoded_words.append(data['train']['output_lang'].index2word[elem])\n",
    "        if elem == model_config.EOS_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = Variable(torch.LongTensor([model_config.SOS_token] * 8)).to(model_config.device)\n",
    "yo = torch.stack((yo, topi.squeeze(), topi.squeeze()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = torch.autograd.Variable(torch.LongTensor(np.repeat([2], len(x['input_length'])))).to(model_config.device)\n",
    "mask = seq_range < x['input_length']\n",
    "loss = -torch.gather(decoder_output, dim=1, index=input_var.unsqueeze(1)).squeeze() * mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4193, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum() / torch.sum(loss > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(loss > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(x['input'], x['input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = None\n",
    "if decoder.attention:\n",
    "    context = Variable(torch.zeros(encoder_output.size(0), encoder_output.size(2))).unsqueeze(1).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, context, weights = decoder(input_var, encoder_hidden, encoder_output, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item() * \\\n",
    "            len(batch['label']) / len(train_loader.dataset)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30a2084915f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-df8527ea006d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(translation_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(translation_model, optimizer, train_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
