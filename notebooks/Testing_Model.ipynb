{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from nlpclass.config import model_config\n",
    "from nlpclass.data.data_utils import TranslationDataset, text_collate_func\n",
    "from nlpclass.models.evaluation_utils import bleu_eval, output_to_translations\n",
    "from nlpclass.models.models import DecoderRNN, EncoderCNN, EncoderRNN, TranslationModel\n",
    "from nlpclass.models.training_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_DIR = osp.join(CURRENT_PATH, '..', 'data')\n",
    "MODEL_DIR = osp.join(CURRENT_PATH, '..','models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "Counted words:\n",
      "eng 6948\n",
      "vi 7864\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3562\n",
      "vi 3678\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3361\n",
      "vi 3518\n"
     ]
    }
   ],
   "source": [
    "data, data_loaders, max_length = load_data('vi', batch_size=24, subsample=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderCNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2).to(model_config.device)\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=False).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True).to(model_config.device)\n",
    "if encoder.bidirectional:\n",
    "    multiplier = 2\n",
    "else:\n",
    "    multiplier = 1\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=multiplier * 128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=True).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, target, criterion):\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    target_flat = target.view(-1, 1).squeeze()\n",
    "    return criterion(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447ce8aa89134f288f2eb45798b51eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02081002351728782 0.8948125911905823 4.485920429229736\n",
      "0.0044826690323597485 0.8900639047695108 5.66490364074707\n",
      "0.002396033676938403 0.7689059486316749 4.440055847167969\n",
      "0.0020469437754174406 0.6683712315102626 5.741753578186035\n",
      "0.030462189321514982 1.6411576962863095 5.820199966430664\n",
      "0.015384916092793247 0.9789257846466267 5.803258895874023\n",
      "0.018016021447575324 0.932944343766468 4.2251105308532715\n",
      "0.0028335764521192513 0.5736442023936066 4.7286272048950195\n",
      "0.0005778798171358665 0.7704430019160755 4.639809608459473\n",
      "0.0045128316964229784 0.8166897947549911 4.530723571777344\n",
      "0.0007745496976682681 0.8650351183934487 5.834169387817383\n",
      "0.0009779453903998362 1.017596168887139 4.33758544921875\n",
      "0.005012853256518536 1.4099501178104217 4.563002586364746\n",
      "0.000859077534207842 1.0878336867027958 5.872256755828857\n",
      "0.01320901619555255 0.956627219322167 4.43832540512085\n",
      "0.0036146183806488623 0.7851070436404702 5.93349552154541\n",
      "0.0023437373858420847 0.8426486490998301 4.4117889404296875\n",
      "0.0007968365538384509 0.8411792035318777 4.489053726196289\n",
      "0.004410786787405969 0.8922012108727677 5.815210819244385\n",
      "0.00034702826069020834 0.8869901563849883 4.492777347564697\n",
      "0.0012822854960349457 0.7631178368827516 5.879583358764648\n",
      "0.00036355141292187203 0.9798954068183151 4.694865703582764\n",
      "0.0015578595506214447 0.7144996872239222 5.506135940551758\n",
      "0.0007097000456671197 0.8094740521082182 5.545690536499023\n",
      "0.0009810009051364672 0.8858163516023609 5.770859241485596\n",
      "0.0029950412033805745 1.1151943275928435 4.648115634918213\n",
      "0.0005708444330594888 0.6423384465033317 5.84233283996582\n",
      "0.0006231053521452223 1.325350327102313 4.597518444061279\n",
      "0.0009974724343941865 0.8910329194513416 4.284238815307617\n",
      "0.0005171031272813879 0.9192326167776755 5.891429901123047\n",
      "0.0007419222468691988 1.0139513475692312 5.532558917999268\n",
      "0.0015143452532871368 0.8076244190226687 5.731724739074707\n",
      "0.0012566038797689257 0.8205661807582828 4.528514862060547\n",
      "0.0007893190879698133 0.9714862093751757 5.623291015625\n",
      "0.0029049949295172147 0.7964219062298584 4.5920329093933105\n",
      "0.003696165194048239 0.9227481552899928 5.66772985458374\n",
      "0.007531714277047851 1.0710807355551288 5.628490924835205\n",
      "0.002909264812180784 1.1414591870623492 5.210489749908447\n",
      "0.001799778659140862 0.7996785083965234 4.54350471496582\n",
      "0.002305900428935616 0.8078239587941601 5.840023994445801\n",
      "0.0009046529630202112 1.1537188454173406 4.388874053955078\n",
      "0.031128935972644614 1.0751012637848487 4.42408561706543\n",
      "0.005835558793190358 0.9780707039988884 4.870616912841797\n",
      "0.009321818077536318 0.8134791505478496 4.678349018096924\n",
      "0.0021773548727788325 0.7672671097896182 5.753867149353027\n",
      "0.00039128701145264085 1.007294805250645 5.995056629180908\n",
      "0.0015656606309311094 0.8633750142387184 4.291684150695801\n",
      "0.0047308323636156375 0.7968207399755831 5.895752906799316\n",
      "0.008306352868732454 0.766664697674161 5.950789451599121\n",
      "0.016766530393412447 1.4153205605420967 5.548879146575928\n",
      "0.007854783262719937 1.1770186599511396 5.6263813972473145\n",
      "0.002031930998645152 1.0646524159163768 4.652364253997803\n",
      "0.007164422236742834 0.6690603488956781 4.619311332702637\n",
      "0.000369507189109007 0.6650710793573285 4.6625285148620605\n",
      "0.002047310975768709 0.6541670467911631 4.5841546058654785\n",
      "0.0008917851392177641 0.633225484820846 5.7597432136535645\n",
      "0.0023356493604095693 0.947826293100935 5.89835786819458\n",
      "0.008829394478462375 1.326023511678868 5.701194763183594\n",
      "0.0011507810226349 0.7159003209339465 5.911569595336914\n",
      "0.0004404068897220333 0.8755474006448385 5.857332706451416\n",
      "0.004926279915678246 1.417782948573273 5.689388275146484\n",
      "0.0006542964235469219 0.6660298596054681 4.415598392486572\n",
      "0.0004073849965728294 0.6746817236365039 4.547499179840088\n",
      "0.0023490558080804867 0.9221508341879031 5.622654438018799\n",
      "0.008244326317431303 1.0301447844524825 4.415168762207031\n",
      "0.0001966515568351318 0.7809808891583604 4.674655437469482\n",
      "0.0021263339132385145 1.0052132214369054 5.68926477432251\n",
      "0.0019125769289529337 0.9981983099865142 4.252735137939453\n",
      "0.000860302346400422 0.5717260033662858 4.803892612457275\n",
      "0.00021554815222651444 0.7433400742183717 5.676790237426758\n",
      "0.0004945313682836572 0.8133164991904074 5.697444915771484\n",
      "0.006415647317437658 1.0246762600531896 4.2907233238220215\n",
      "0.0010139889318075683 1.231964828751154 5.780658721923828\n",
      "0.0011474569321233419 0.6764843363992277 4.703683853149414\n",
      "0.0006538728513853803 0.8291133668493329 5.625680923461914\n",
      "0.00016860540601824193 0.652142830022109 5.793490409851074\n",
      "0.0016023998959335418 1.0752063517620842 4.24049711227417\n",
      "0.003284253539952066 0.8270224315752798 4.477046012878418\n",
      "0.0012776044431671396 0.6995980256037828 4.743544578552246\n",
      "0.001082347871427198 0.6970479913000093 4.669391632080078\n",
      "0.001244167362307119 0.7911047372390034 4.478017807006836\n",
      "0.002259043511459469 0.7973608482056521 5.7317795753479\n",
      "0.001276685318483681 0.7677562688560645 5.760125160217285\n",
      "0.00036688625194152214 0.6005104979662576 4.555268287658691\n",
      "0.0015993367872365629 0.7931139031758272 5.740706443786621\n",
      "0.005659893729964006 0.8692750452753343 4.47896671295166\n",
      "0.0018457345538854795 0.6007995274619462 5.759456157684326\n",
      "0.0014273319591545186 0.783038643867576 4.339552402496338\n",
      "0.0006882896996037989 0.5477802158504611 4.65769100189209\n",
      "0.004322378406472749 0.5760134357992023 4.69003438949585\n",
      "0.0008770023608073631 0.6411634468330893 5.7597174644470215\n",
      "0.0015653446397302531 0.7436706622427465 4.584688663482666\n",
      "0.0011820923623184956 0.8352831743810134 4.363123416900635\n",
      "0.004420370987813067 0.817246278867831 4.401227951049805\n",
      "0.0004169237381913327 0.5688170907936407 5.964644432067871\n",
      "0.002175315649436955 1.5645155824005308 5.517765998840332\n",
      "0.0001085278685217373 0.6401006316017188 5.782923221588135\n",
      "0.0038110052610634687 0.6988433376947023 4.585474967956543\n",
      "0.0005419914465433921 1.0106435901395858 4.652859687805176\n",
      "0.0014711444192478417 0.7729262983961974 5.826025485992432\n",
      "0.0014165157084317403 0.9941325790443143 5.810582637786865\n",
      "0.0005052366785933073 0.9531800800718395 5.929654121398926\n",
      "0.0016093628843115077 0.6595774179817221 4.740067958831787\n",
      "0.0008402517500109162 0.6030032091467378 6.118503570556641\n",
      "0.0012697489770713648 0.7188792814710074 4.788527965545654\n",
      "0.002321968956767698 0.8804509252732239 4.601807594299316\n",
      "0.0002549855080914965 0.5665241738960599 6.199784278869629\n",
      "0.0076789537267112915 0.8380134716252988 4.623838901519775\n",
      "0.00037421383208105735 1.0044797227833309 4.372270584106445\n",
      "0.008972239104034253 0.9828292904056832 4.576758861541748\n",
      "0.0010830698018108036 0.6067083799540274 6.118342399597168\n",
      "0.0020351737223419197 0.9390527549047597 4.388131618499756\n",
      "0.0004836175332650486 0.7985479745437676 4.848337173461914\n",
      "0.0029779388807425126 0.6385563493096071 5.788933753967285\n",
      "0.005390786927015847 0.7529100679869581 5.952551364898682\n",
      "0.005169214810972949 1.4544942434907617 5.53000545501709\n",
      "0.025423428884020226 1.4799360602544862 5.884418487548828\n",
      "0.0015106203917726211 1.027441659691468 4.5447187423706055\n",
      "0.001469850418371826 0.9304430327899028 5.643752574920654\n",
      "0.0010387841766322638 1.0293207241207645 5.93812894821167\n",
      "0.016706428937446578 1.4473435017733292 4.713708877563477\n",
      "0.004299465562338113 0.9416669833296861 4.540255069732666\n",
      "0.005896594798461164 1.1290436193139248 4.854610919952393\n",
      "0.002214489902629316 0.8289118657883985 5.979776859283447\n",
      "0.002204477950946847 0.631060134173158 4.487428665161133\n",
      "0.0031312469550060186 1.4254495346031906 5.549727916717529\n",
      "0.006626991362101766 0.5171680856082297 4.935212135314941\n",
      "0.008787946394193542 0.976543782664386 4.5413360595703125\n",
      "0.0015817705973458528 0.7501147354698467 5.995208740234375\n",
      "0.007736577687814064 0.915515840023898 4.497888088226318\n",
      "0.000853684073519916 0.8456130424074987 6.071440696716309\n",
      "0.045998723020440946 1.3860131039571197 4.389220237731934\n",
      "0.0005035581399477261 0.6290014480445978 4.666289806365967\n",
      "0.00047625026828083413 0.7863396662323228 6.034376621246338\n",
      "0.036210604542367 2.2828925563846854 5.478071212768555\n",
      "0.002117361365147913 0.6938153953727999 4.542389392852783\n",
      "0.002134054702625368 0.7710966676912592 4.724905967712402\n",
      "0.011628243144559564 1.4142067677382695 5.5353007316589355\n",
      "0.0020830108684598424 0.981793594416584 5.978837490081787\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(25)):\n",
    "    for batch in data_loaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        logits = translation_model(batch)\n",
    "        loss = calc_loss(logits, batch['target'], criterion)\n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_norm = 0\n",
    "        for p in translation_model.encoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            encoder_norm += param_norm.item() ** 2\n",
    "        decoder_norm = 0\n",
    "        for p in translation_model.decoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            decoder_norm += param_norm.item() ** 2\n",
    "            \n",
    "        print(encoder_norm, decoder_norm, loss.item())\n",
    "            \n",
    "        clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                                   translation_model.parameters()), 5.0)\n",
    "        \n",
    "        optimizer.step() \n",
    "    original, translation = evaluate(translation_model, data, data_loaders, dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2907983665913475\n",
      "[('and i think that you can do you can do it .', 'and a lot of that learning i think came from being on that farm because when i was working on the farm wed have to use what was around us wed have to use the environment and there was no such thing as something cant be done because youre in an environment where if you cant do what you need to do you can die and you know i had seen that sort of thing happen .'), ('throughout all a new york .', 'throughout all of this what i would ultimately realize was that each voice was closely related to aspects of myself and that each of them carried overwhelming emotions that id never had an opportunity to process or resolve memories of sexual trauma and abuse of anger shame guilt low self worth .')]\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.greedy(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(list(zip(translations[0:2], original[0:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-04a482f71426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_to_translations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_to_translations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             enocoder_output_one = encoder_output[sentence, :, :].unsqueeze(\n\u001b[0m\u001b[1;32m    357\u001b[0m                 dim=0)\n\u001b[1;32m    358\u001b[0m             \u001b[0mdecoder_hidden_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.beam_search(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "input_seq = x['input']\n",
    "target_seq = x['target']\n",
    "input_length = x['input_length']\n",
    "target_length = x['target_length']\n",
    "\n",
    "encoded_input, hidden = translation_model.encoder.forward(input_seq, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6125, -0.5094,  0.1136,  ...,  0.2936, -0.0332, -0.5566],\n",
       "        [-0.2966, -0.5157,  0.0630,  ...,  0.6734,  0.0263, -0.9648],\n",
       "        [ 0.3257, -1.1140,  0.3586,  ...,  0.7310, -0.7097, -0.5748],\n",
       "        ...,\n",
       "        [-0.3053, -0.1229,  0.2143,  ..., -0.5936, -0.5418, -0.0655],\n",
       "        [-0.2868, -0.2641,  0.6324,  ..., -0.5235, -0.4746, -0.1487],\n",
       "        [-0.0230, -0.0655,  0.1169,  ..., -0.4210,  0.3063,  0.4462]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.9659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-2)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(x)\n",
    "    loss = calc_loss(logits, x['target'], criterion)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, data_loaders, dataset_type='dev', max_batches=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        original_strings = []\n",
    "        translated_strings = []\n",
    "        for i, batch in enumerate(data_loaders[dataset_type]):\n",
    "            if i > max_batches:\n",
    "                break\n",
    "            logits = translation_model(batch)\n",
    "            epoch_loss = calc_loss(logits, batch['target'], criterion)\n",
    "            original = output_to_translations(batch['target'], data['train'])\n",
    "            translations = output_to_translations(model.greedy(batch), data['train'])\n",
    "            original_strings.extend(original)\n",
    "            translated_strings.extend(translations)\n",
    "        bleu = bleu_eval(original_strings, translated_strings)\n",
    "        model.train()\n",
    "        print(epoch_loss)\n",
    "        print(bleu)\n",
    "        \n",
    "        return original_strings, translated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)\n",
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34410a3c73c44d89f2e6cddd5d165c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1389), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.1450, device='cuda:0')\n",
      "0.0008142795832761162\n",
      "tensor(9.0464, device='cuda:0')\n",
      "0.0033784249080402885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-bf6d2f87ea3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#evaluate(translation_model, data, data_loaders, dataset_type='train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         decoder_outputs = Variable(torch.zeros(\n\u001b[0;32m--> 166\u001b[0;31m             model_config.max_length + 1, batch_size, self.decoder.output_size)).to(model_config.device)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm_notebook(data_loaders['train'])):\n",
    "    if i % 500 == 0:\n",
    "        evaluate(translation_model, data, data_loaders)\n",
    "        #evaluate(translation_model, data, data_loaders, dataset_type='train')\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(batch)\n",
    "    loss = calc_loss(logits, batch['target'], criterion)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strings, translated_strings = evaluate(translation_model, data, data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball be later but of volumes all. hope. answer. only were',\n",
       " 'be this. 65. know what must truth. i most',\n",
       " 'games be practical everybody pins your needles all forward careful were',\n",
       " 'i moment. it attack. be sorrows. ten.',\n",
       " 'canadian be appointment careful laugh. no truth. something time were',\n",
       " 'beautiful cupboard. hot. wine these',\n",
       " 'much. but how bitter really dishonesty fed recently',\n",
       " 'applied all else fed to climate husbands. matter. key',\n",
       " 'but they answer. perfect. today. tape',\n",
       " 'i is invented i situation getting powers your few']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = translation_model.greedy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in predictions.cpu().numpy():\n",
    "    decoded_words = []\n",
    "    for elem in row[1:]:\n",
    "        decoded_words.append(data['train']['output_lang'].index2word[elem])\n",
    "        if elem == model_config.EOS_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = Variable(torch.LongTensor([model_config.SOS_token] * 8)).to(model_config.device)\n",
    "yo = torch.stack((yo, topi.squeeze(), topi.squeeze()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = torch.autograd.Variable(torch.LongTensor(np.repeat([2], len(x['input_length'])))).to(model_config.device)\n",
    "mask = seq_range < x['input_length']\n",
    "loss = -torch.gather(decoder_output, dim=1, index=input_var.unsqueeze(1)).squeeze() * mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4193, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum() / torch.sum(loss > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(loss > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(x['input'], x['input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = None\n",
    "if decoder.attention:\n",
    "    context = Variable(torch.zeros(encoder_output.size(0), encoder_output.size(2))).unsqueeze(1).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, context, weights = decoder(input_var, encoder_hidden, encoder_output, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item() * \\\n",
    "            len(batch['label']) / len(train_loader.dataset)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30a2084915f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-df8527ea006d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(translation_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(translation_model, optimizer, train_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
