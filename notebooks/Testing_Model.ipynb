{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from nlpclass.config import model_config\n",
    "from nlpclass.data.data_utils import TranslationDataset, text_collate_func\n",
    "from nlpclass.models.evaluation_utils import bleu_eval, output_to_translations\n",
    "from nlpclass.models.models import DecoderRNN, EncoderCNN, EncoderRNN, TranslationModel\n",
    "from nlpclass.models.training_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_DIR = osp.join(CURRENT_PATH, '..', 'data')\n",
    "MODEL_DIR = osp.join(CURRENT_PATH, '..','models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "Counted words:\n",
      "eng 6638\n",
      "vi 7615\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3562\n",
      "vi 3678\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3361\n",
      "vi 3518\n"
     ]
    }
   ],
   "source": [
    "data, data_loaders, max_length = load_data('vi', batch_size=24, subsample=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderCNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2).to(model_config.device)\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=False).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True).to(model_config.device)\n",
    "if encoder.bidirectional:\n",
    "    multiplier = 2\n",
    "else:\n",
    "    multiplier = 1\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=multiplier * 128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=True).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, target, criterion):\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    target_flat = target.view(-1, 1).squeeze()\n",
    "    return criterion(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589fd6303324463291711dbff3212340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 256])\n",
      "0.016014057126446355 12.988488699648784 9.250019073486328\n",
      "torch.Size([1, 24, 256])\n",
      "0.01423461857956431 0.4711033083514328 8.920844078063965\n",
      "torch.Size([1, 24, 256])\n",
      "0.0601824821255616 2.6491856301590193 8.81812572479248\n",
      "torch.Size([1, 24, 256])\n",
      "0.18688966740129787 17.011739338742153 8.651341438293457\n",
      "torch.Size([1, 24, 256])\n",
      "0.007425567136447166 8.28847112765077 7.967498302459717\n",
      "torch.Size([1, 24, 256])\n",
      "0.012969294503563617 7.461649338906267 7.720865726470947\n",
      "torch.Size([1, 24, 256])\n",
      "0.025176331576022337 7.271350982146542 7.408128261566162\n",
      "torch.Size([1, 24, 256])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-257ee7664189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mencoder_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(25)):\n",
    "    for batch in data_loaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        logits = translation_model(batch)\n",
    "        loss = calc_loss(logits, batch['target'], criterion)\n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_norm = 0\n",
    "        for p in translation_model.encoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            encoder_norm += param_norm.item() ** 2\n",
    "        decoder_norm = 0\n",
    "        for p in translation_model.decoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            decoder_norm += param_norm.item() ** 2\n",
    "            \n",
    "        print(encoder_norm, decoder_norm, loss.item())\n",
    "            \n",
    "        clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                                   translation_model.parameters()), 5.0)\n",
    "        \n",
    "        optimizer.step() \n",
    "    original, translation = evaluate(translation_model, data, data_loaders, dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.7832,  1.5971,  1.6313,  ..., -1.6434, -0.7847, -1.1910],\n",
      "        [ 0.7029, -0.8077, -0.0809,  ...,  0.1486,  2.2126,  1.0358],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 1.1616, -0.5320,  0.9628,  ...,  1.1755, -1.4453,  0.2851],\n",
      "        [-1.0434, -0.7357, -1.4873,  ..., -0.2884, -1.0221, -0.1769],\n",
      "        [ 1.8304,  1.2250,  0.5090,  ..., -0.6980, -0.1712,  0.9305]],\n",
      "       device='cuda:0', requires_grad=True) None\n",
      "HUYYY\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0019,  0.0514,  0.0042],\n",
      "         [-0.0161,  0.0248,  0.0257],\n",
      "         [ 0.0093, -0.0122,  0.0122],\n",
      "         ...,\n",
      "         [-0.0010,  0.0190, -0.0481],\n",
      "         [-0.0156, -0.0529,  0.0567],\n",
      "         [ 0.0176, -0.0385, -0.0022]],\n",
      "\n",
      "        [[-0.0157,  0.0419, -0.0041],\n",
      "         [-0.0290,  0.0321, -0.0371],\n",
      "         [ 0.0193,  0.0435,  0.0241],\n",
      "         ...,\n",
      "         [ 0.0399,  0.0328, -0.0190],\n",
      "         [ 0.0063, -0.0179,  0.0031],\n",
      "         [-0.0096,  0.0472, -0.0531]],\n",
      "\n",
      "        [[ 0.0376,  0.0469,  0.0315],\n",
      "         [-0.0173,  0.0391, -0.0571],\n",
      "         [-0.0216, -0.0236,  0.0088],\n",
      "         ...,\n",
      "         [-0.0038,  0.0315, -0.0395],\n",
      "         [ 0.0351,  0.0050, -0.0478],\n",
      "         [ 0.0424,  0.0191, -0.0573]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0391, -0.0331,  0.0290],\n",
      "         [-0.0009, -0.0412, -0.0230],\n",
      "         [-0.0203, -0.0065,  0.0109],\n",
      "         ...,\n",
      "         [ 0.0113,  0.0383, -0.0158],\n",
      "         [-0.0489,  0.0318, -0.0198],\n",
      "         [ 0.0569, -0.0205, -0.0269]],\n",
      "\n",
      "        [[-0.0048,  0.0358,  0.0193],\n",
      "         [-0.0293,  0.0460,  0.0508],\n",
      "         [ 0.0238,  0.0419, -0.0425],\n",
      "         ...,\n",
      "         [-0.0103, -0.0399,  0.0538],\n",
      "         [-0.0158, -0.0181, -0.0554],\n",
      "         [-0.0082, -0.0490, -0.0268]],\n",
      "\n",
      "        [[ 0.0181,  0.0316, -0.0314],\n",
      "         [ 0.0210,  0.0095,  0.0485],\n",
      "         [-0.0042,  0.0111,  0.0351],\n",
      "         ...,\n",
      "         [ 0.0385,  0.0575,  0.0475],\n",
      "         [-0.0430,  0.0425,  0.0146],\n",
      "         [ 0.0371,  0.0193,  0.0259]]], device='cuda:0', requires_grad=True) None\n",
      "HUYYY\n",
      "Parameter containing:\n",
      "tensor([ 0.0030, -0.0024,  0.0029, -0.0464,  0.0361, -0.0493, -0.0340,  0.0112,\n",
      "        -0.0106, -0.0288, -0.0553,  0.0479, -0.0446, -0.0435, -0.0467,  0.0155,\n",
      "        -0.0117,  0.0104, -0.0379, -0.0059,  0.0410, -0.0373, -0.0501, -0.0372,\n",
      "         0.0173, -0.0337, -0.0394,  0.0482, -0.0023,  0.0402, -0.0301,  0.0007,\n",
      "         0.0406, -0.0454, -0.0515, -0.0307,  0.0275,  0.0483,  0.0143, -0.0391,\n",
      "         0.0176, -0.0223, -0.0262, -0.0489,  0.0246, -0.0565,  0.0417, -0.0313,\n",
      "         0.0530, -0.0397,  0.0491,  0.0458,  0.0212, -0.0427,  0.0573,  0.0570,\n",
      "         0.0517,  0.0547, -0.0226, -0.0479, -0.0490,  0.0206,  0.0222,  0.0390,\n",
      "         0.0253,  0.0456, -0.0260,  0.0429, -0.0003,  0.0391,  0.0537, -0.0234,\n",
      "        -0.0228,  0.0287, -0.0331,  0.0208, -0.0021,  0.0067, -0.0329,  0.0442,\n",
      "         0.0106, -0.0439,  0.0116, -0.0270, -0.0143,  0.0321,  0.0169,  0.0161,\n",
      "         0.0203,  0.0180,  0.0163, -0.0244, -0.0506,  0.0551,  0.0488,  0.0557,\n",
      "        -0.0170, -0.0551,  0.0227, -0.0369,  0.0388,  0.0434, -0.0148,  0.0266,\n",
      "        -0.0015,  0.0280,  0.0073, -0.0208,  0.0137, -0.0049,  0.0386, -0.0444,\n",
      "        -0.0501,  0.0555,  0.0437, -0.0172,  0.0417,  0.0211,  0.0286, -0.0405,\n",
      "        -0.0078, -0.0379, -0.0203,  0.0071, -0.0405,  0.0382, -0.0217, -0.0238],\n",
      "       device='cuda:0', requires_grad=True) None\n",
      "HUYYY\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0192,  0.0202, -0.0243],\n",
      "         [ 0.0125,  0.0237,  0.0469],\n",
      "         [ 0.0167, -0.0039, -0.0141],\n",
      "         ...,\n",
      "         [-0.0125, -0.0383,  0.0098],\n",
      "         [ 0.0462, -0.0487,  0.0471],\n",
      "         [ 0.0402,  0.0036, -0.0414]],\n",
      "\n",
      "        [[-0.0338, -0.0018, -0.0227],\n",
      "         [ 0.0274, -0.0433, -0.0240],\n",
      "         [-0.0386,  0.0247,  0.0281],\n",
      "         ...,\n",
      "         [ 0.0441, -0.0424,  0.0231],\n",
      "         [-0.0382, -0.0192, -0.0410],\n",
      "         [-0.0271,  0.0068,  0.0328]],\n",
      "\n",
      "        [[-0.0080,  0.0422,  0.0243],\n",
      "         [ 0.0089, -0.0446,  0.0186],\n",
      "         [-0.0453,  0.0359, -0.0505],\n",
      "         ...,\n",
      "         [-0.0039, -0.0268, -0.0307],\n",
      "         [-0.0040,  0.0247,  0.0153],\n",
      "         [-0.0506,  0.0452, -0.0023]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0209,  0.0436, -0.0500],\n",
      "         [ 0.0125,  0.0031, -0.0476],\n",
      "         [ 0.0162,  0.0058,  0.0072],\n",
      "         ...,\n",
      "         [ 0.0075,  0.0308,  0.0248],\n",
      "         [ 0.0092, -0.0252,  0.0229],\n",
      "         [-0.0200, -0.0221,  0.0042]],\n",
      "\n",
      "        [[ 0.0173, -0.0257,  0.0085],\n",
      "         [-0.0263,  0.0019, -0.0089],\n",
      "         [-0.0333, -0.0282,  0.0369],\n",
      "         ...,\n",
      "         [ 0.0321,  0.0003,  0.0162],\n",
      "         [-0.0065,  0.0091, -0.0084],\n",
      "         [ 0.0039, -0.0085,  0.0426]],\n",
      "\n",
      "        [[-0.0510, -0.0007, -0.0133],\n",
      "         [-0.0225,  0.0467,  0.0231],\n",
      "         [-0.0229, -0.0036, -0.0403],\n",
      "         ...,\n",
      "         [ 0.0123,  0.0224, -0.0294],\n",
      "         [ 0.0272,  0.0096,  0.0104],\n",
      "         [-0.0213,  0.0436,  0.0146]]], device='cuda:0', requires_grad=True) None\n",
      "HUYYY\n",
      "Parameter containing:\n",
      "tensor([ 0.0093,  0.0049,  0.0189, -0.0483, -0.0189,  0.0292,  0.0090, -0.0507,\n",
      "        -0.0240, -0.0492, -0.0447, -0.0448,  0.0377, -0.0284, -0.0149, -0.0357,\n",
      "        -0.0246,  0.0249, -0.0492,  0.0002,  0.0038, -0.0187,  0.0387,  0.0302,\n",
      "        -0.0475, -0.0486,  0.0478,  0.0289,  0.0355, -0.0101, -0.0366,  0.0375,\n",
      "        -0.0137,  0.0253, -0.0251,  0.0421, -0.0390, -0.0066,  0.0232,  0.0292,\n",
      "         0.0482, -0.0218, -0.0080,  0.0003, -0.0320, -0.0422,  0.0130, -0.0492,\n",
      "         0.0004, -0.0467, -0.0188, -0.0083, -0.0066,  0.0440,  0.0301,  0.0110,\n",
      "         0.0055, -0.0416,  0.0137,  0.0086, -0.0455, -0.0424,  0.0001, -0.0101,\n",
      "         0.0337, -0.0047,  0.0133,  0.0389,  0.0065, -0.0013, -0.0014, -0.0434,\n",
      "         0.0048,  0.0319,  0.0281,  0.0462, -0.0192,  0.0478, -0.0205,  0.0453,\n",
      "        -0.0036, -0.0348, -0.0193,  0.0085, -0.0055, -0.0067, -0.0216,  0.0381,\n",
      "         0.0396,  0.0408,  0.0399,  0.0162,  0.0238,  0.0146, -0.0339, -0.0199,\n",
      "        -0.0285,  0.0173, -0.0132,  0.0264, -0.0188,  0.0424,  0.0207, -0.0201,\n",
      "        -0.0413,  0.0232, -0.0204, -0.0079, -0.0509,  0.0157, -0.0426,  0.0130,\n",
      "        -0.0386,  0.0506,  0.0465,  0.0256,  0.0115,  0.0490,  0.0447,  0.0496,\n",
      "         0.0138, -0.0026, -0.0375, -0.0267,  0.0308, -0.0309,  0.0387,  0.0411],\n",
      "       device='cuda:0', requires_grad=True) None\n",
      "HUYYY\n"
     ]
    }
   ],
   "source": [
    "for p in translation_model.encoder.parameters():\n",
    "    print(p, p.grad)\n",
    "    if p.grad is None:\n",
    "        print('HUYYY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv1d(100, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_model.encoder.conv_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.57723576781832\n",
      "[('well i 97 pleased pleased pleased pleased to report of to share the task of to share with experiments and share the past illnesses of mental illnesses of mental illnesses of mental illnesses of depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression depression', 'well today im very pleased to report to you that there have been many experiments in task shifting in mental health care across the developing world over the past decade and i want to share with you the findings of three particular such experiments all three of which focused on depression the most common of all mental illnesses .'), ('so if youre going to you your passion to you you your passion to you your passion to you your passion or youre trying to figure out to your own youre trying to figure out to your own youre .', 'so whether youre looking for a husband or a wife or youre trying to find your passion or youre trying to start a business all you have to really do is figure out your own framework and play by your own rules and feel free to be as picky as you want .')]\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.greedy(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(list(zip(translations[0:2], original[0:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.beam_search(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "input_seq = x['input']\n",
    "target_seq = x['target']\n",
    "input_length = x['input_length']\n",
    "target_length = x['target_length']\n",
    "\n",
    "encoded_input, hidden = translation_model.encoder.forward(input_seq, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6125, -0.5094,  0.1136,  ...,  0.2936, -0.0332, -0.5566],\n",
       "        [-0.2966, -0.5157,  0.0630,  ...,  0.6734,  0.0263, -0.9648],\n",
       "        [ 0.3257, -1.1140,  0.3586,  ...,  0.7310, -0.7097, -0.5748],\n",
       "        ...,\n",
       "        [-0.3053, -0.1229,  0.2143,  ..., -0.5936, -0.5418, -0.0655],\n",
       "        [-0.2868, -0.2641,  0.6324,  ..., -0.5235, -0.4746, -0.1487],\n",
       "        [-0.0230, -0.0655,  0.1169,  ..., -0.4210,  0.3063,  0.4462]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.9659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-2)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(x)\n",
    "    loss = calc_loss(logits, x['target'], criterion)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, data_loaders, dataset_type='dev', max_batches=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        original_strings = []\n",
    "        translated_strings = []\n",
    "        for i, batch in enumerate(data_loaders[dataset_type]):\n",
    "            if i > max_batches:\n",
    "                break\n",
    "            logits = translation_model(batch)\n",
    "            epoch_loss = calc_loss(logits, batch['target'], criterion)\n",
    "            original = output_to_translations(batch['target'], data['train'])\n",
    "            translations = output_to_translations(model.greedy(batch), data['train'])\n",
    "            original_strings.extend(original)\n",
    "            translated_strings.extend(translations)\n",
    "        bleu = bleu_eval(original_strings, translated_strings)\n",
    "        model.train()\n",
    "        print(epoch_loss)\n",
    "        print(bleu)\n",
    "        \n",
    "        return original_strings, translated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)\n",
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34410a3c73c44d89f2e6cddd5d165c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1389), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.1450, device='cuda:0')\n",
      "0.0008142795832761162\n",
      "tensor(9.0464, device='cuda:0')\n",
      "0.0033784249080402885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-bf6d2f87ea3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#evaluate(translation_model, data, data_loaders, dataset_type='train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         decoder_outputs = Variable(torch.zeros(\n\u001b[0;32m--> 166\u001b[0;31m             model_config.max_length + 1, batch_size, self.decoder.output_size)).to(model_config.device)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm_notebook(data_loaders['train'])):\n",
    "    if i % 500 == 0:\n",
    "        evaluate(translation_model, data, data_loaders)\n",
    "        #evaluate(translation_model, data, data_loaders, dataset_type='train')\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(batch)\n",
    "    loss = calc_loss(logits, batch['target'], criterion)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strings, translated_strings = evaluate(translation_model, data, data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball be later but of volumes all. hope. answer. only were',\n",
       " 'be this. 65. know what must truth. i most',\n",
       " 'games be practical everybody pins your needles all forward careful were',\n",
       " 'i moment. it attack. be sorrows. ten.',\n",
       " 'canadian be appointment careful laugh. no truth. something time were',\n",
       " 'beautiful cupboard. hot. wine these',\n",
       " 'much. but how bitter really dishonesty fed recently',\n",
       " 'applied all else fed to climate husbands. matter. key',\n",
       " 'but they answer. perfect. today. tape',\n",
       " 'i is invented i situation getting powers your few']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = translation_model.greedy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in predictions.cpu().numpy():\n",
    "    decoded_words = []\n",
    "    for elem in row[1:]:\n",
    "        decoded_words.append(data['train']['output_lang'].index2word[elem])\n",
    "        if elem == model_config.EOS_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = Variable(torch.LongTensor([model_config.SOS_token] * 8)).to(model_config.device)\n",
    "yo = torch.stack((yo, topi.squeeze(), topi.squeeze()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = torch.autograd.Variable(torch.LongTensor(np.repeat([2], len(x['input_length'])))).to(model_config.device)\n",
    "mask = seq_range < x['input_length']\n",
    "loss = -torch.gather(decoder_output, dim=1, index=input_var.unsqueeze(1)).squeeze() * mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4193, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum() / torch.sum(loss > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(loss > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(x['input'], x['input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = None\n",
    "if decoder.attention:\n",
    "    context = Variable(torch.zeros(encoder_output.size(0), encoder_output.size(2))).unsqueeze(1).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, context, weights = decoder(input_var, encoder_hidden, encoder_output, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item() * \\\n",
    "            len(batch['label']) / len(train_loader.dataset)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30a2084915f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-df8527ea006d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(translation_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(translation_model, optimizer, train_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
