{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from nlpclass.config import model_config\n",
    "from nlpclass.data.data_utils import TranslationDataset, text_collate_func\n",
    "from nlpclass.models.evaluation_utils import bleu_eval, output_to_translations\n",
    "from nlpclass.models.models import DecoderRNN, EncoderRNN, TranslationModel\n",
    "from nlpclass.models.training_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_DIR = osp.join(CURRENT_PATH, '..', 'data')\n",
    "MODEL_DIR = osp.join(CURRENT_PATH, '..','models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "Counted words:\n",
      "eng 17735\n",
      "vi 25085\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3039\n",
      "vi 3678\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 2890\n",
      "vi 3518\n"
     ]
    }
   ],
   "source": [
    "data, data_loaders, max_length = load_data('vi', batch_size=24, subsample=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    bidirectional=False).to(model_config.device)\n",
    "if encoder.bidirectional:\n",
    "    multiplier = 2\n",
    "else:\n",
    "    multiplier = 1\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=multiplier * 128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=True).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, target, criterion):\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    target_flat = target.view(-1, 1).squeeze()\n",
    "    return criterion(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea00f6d377c4410b95835943b90dc605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007507604458805816 6.738299269789271 10.488754272460938\n",
      "0.007891493239795301 0.5306020186921313 10.093649864196777\n",
      "0.011306982743482009 1.2984497982324668 10.039058685302734\n",
      "0.023662760823424375 2.7244228574921108 9.905583381652832\n",
      "0.2613200514727498 42.728482684429 9.854333877563477\n",
      "0.09364816426852679 15.203862072483052 9.403263092041016\n",
      "0.004118706752563063 6.754813569752274 9.004295349121094\n",
      "0.0016209569427997445 8.610039973229759 8.606600761413574\n",
      "0.00163209223259148 6.060230612222734 8.490111351013184\n",
      "0.0011296350984670695 5.144811316260217 8.137129783630371\n",
      "0.0014982526160880103 5.204859946310725 7.672852993011475\n",
      "0.0011092511318612037 3.9895927082342215 7.902891159057617\n",
      "0.001741556854446898 4.104527079466306 7.678654670715332\n",
      "0.0031986945226238762 2.42971230241077 7.369710922241211\n",
      "0.003401476478850956 2.179890618937002 7.533790588378906\n",
      "0.004310077971122467 1.709922460185091 7.622716426849365\n",
      "0.004998833243576786 3.5907971461558734 7.322064399719238\n",
      "0.0036611069605819433 2.9582823346745424 7.138591289520264\n",
      "0.005399196174459582 3.3911289197940104 7.26812744140625\n",
      "0.0038417101511805545 3.288465917626012 7.243836879730225\n",
      "0.0036604556882944735 4.001638840953341 7.412700176239014\n",
      "0.01237613063992976 3.549297431657959 7.405165672302246\n",
      "0.006949605503050995 2.7328715924998894 7.625920295715332\n",
      "0.018384709546561802 4.21093239804719 7.437551498413086\n",
      "0.006508224611652778 4.328110802458544 7.365458011627197\n",
      "0.006205426109778396 5.315206159307659 7.2313995361328125\n",
      "0.029479936990850397 3.961468644181469 7.615307331085205\n",
      "0.022883961589112312 2.7321476830372085 7.316675186157227\n",
      "0.022292556741212853 3.0777921634510195 7.247124671936035\n",
      "0.025664415228805082 2.1022524529356854 7.157416343688965\n",
      "0.030416198312592485 1.456598294468309 7.13325309753418\n",
      "0.05741330197831419 1.792583534066383 7.321832180023193\n",
      "0.02642932863691787 1.4760620055289582 7.19032621383667\n",
      "0.04490779203146557 1.7668144939004946 7.26182222366333\n",
      "0.011644360526836473 1.5531853199782613 7.512668132781982\n",
      "0.012444597035100521 2.2137357031997045 7.002793312072754\n",
      "0.027960849580573453 1.4976430663054865 6.921823978424072\n",
      "0.0024030855335950996 1.751042605677745 7.136415481567383\n",
      "0.0007535480775949861 1.4250046985099518 7.288393020629883\n",
      "0.0038171684458201153 1.7050824104721722 7.118670463562012\n",
      "0.000741326849347771 1.4161803646120839 7.299594879150391\n",
      "0.0010168672161012771 1.721834218669927 7.018181324005127\n",
      "0.0005771856276755153 1.7854683081342078 6.861518859863281\n",
      "0.00042809920686668425 1.5492137753320148 7.070326328277588\n",
      "0.0008894950116333354 1.4087183533385184 6.9052557945251465\n",
      "0.00015843429733728722 1.4306009652671152 7.128064155578613\n",
      "0.000482160226948194 1.509624534172259 6.955847263336182\n",
      "0.0005749814024920514 1.4428757760934352 6.706712245941162\n",
      "0.0004052756115907088 1.6303780128336967 7.052062511444092\n",
      "0.0003501242570574219 1.1037567409582614 6.950560569763184\n",
      "0.002047457179385036 1.339548775257728 6.904448986053467\n",
      "0.0005084465027894083 1.6889860865695876 6.659395217895508\n",
      "0.000277670120386594 2.0880750680774454 6.93446159362793\n",
      "0.0002721045355736074 1.18632936088097 7.023744106292725\n",
      "0.00026209860744830454 1.0962818515489559 7.0839643478393555\n",
      "0.00024670136684849494 1.570193743754116 6.904066562652588\n",
      "0.0004752646163548323 1.526686680541771 6.730161666870117\n",
      "0.00011695670712554839 1.3529024519044963 7.099957466125488\n",
      "0.00015210332574606673 1.5145903325750254 7.135854244232178\n",
      "0.0003763458151845042 1.172312449848028 6.8686981201171875\n",
      "0.0002919904193043976 1.2542168938510132 6.8479204177856445\n",
      "0.0003120475844465537 1.6262510272127608 6.948873519897461\n",
      "0.00017649255946380015 1.2373167101968856 6.744633197784424\n",
      "0.0002014188364143034 1.565399628193119 6.945899486541748\n",
      "0.0002619093413722512 1.7236868717134257 6.4922261238098145\n",
      "0.00024963347417581317 1.5806541946957249 6.331384658813477\n",
      "0.00016743022643675518 2.690118733453418 6.572373390197754\n",
      "0.00018725258450250006 1.446405054838188 6.820343494415283\n",
      "0.0006576160993908073 1.618364764366553 6.56696891784668\n",
      "0.00013724463087549547 1.4771469229907335 6.896428108215332\n",
      "0.00015711657559681091 1.363861076928089 6.738888263702393\n",
      "0.0001562933944786057 1.3267070495675877 6.810435771942139\n",
      "0.000172955396809834 1.46312318246357 6.543805122375488\n",
      "0.0003272297610247514 1.5349602170869916 6.4184088706970215\n",
      "0.0007048564696434077 3.18451160028106 6.731293201446533\n",
      "0.000406725115839578 1.6465318104741657 6.911024570465088\n",
      "0.012130226737673815 9.300625085884661 7.155869483947754\n",
      "0.037441407161472456 3.178427224359131 7.2306599617004395\n",
      "1.7054083052389324 42.70541738328985 6.76585054397583\n",
      "0.012641269017339342 4.884237888805045 6.913751125335693\n",
      "3.504978824072639 1180.9186005045954 6.713639736175537\n",
      "0.004215251748248326 2.5451623897446414 6.554388046264648\n",
      "0.001557637332973815 1.6854302205415108 7.164514064788818\n",
      "0.001976996220871493 1.5255726721637415 7.190893650054932\n",
      "0.008611299188036211 2.1108208091525857 6.7593536376953125\n",
      "0.004491151150606528 1.9922330951368297 7.042577743530273\n",
      "0.04522114732842554 8.681675272445695 6.933210372924805\n",
      "0.010730394655701556 2.6474863304185763 6.622164726257324\n",
      "0.08932082884429475 33.630852850578805 7.094415187835693\n",
      "0.008176739457810847 4.0362992239847415 6.872734546661377\n",
      "0.0004118506858226103 2.0320924590418983 6.794120788574219\n",
      "0.00011647384209602494 2.1508611564835376 7.00739860534668\n",
      "9.720122118141141e-05 1.2487678195836773 6.985831260681152\n",
      "8.8459905876523e-05 1.3751936171905772 7.025599479675293\n",
      "0.00020479067298136638 1.9080488861141258 6.857668876647949\n",
      "0.00013273618908375625 1.8162431499549156 6.748111248016357\n",
      "0.00011636862910131261 1.7868800306110968 6.80952787399292\n",
      "0.00010718493457681501 1.6048818401067848 6.937937259674072\n",
      "0.00015578349331124534 2.439097559084191 6.938679218292236\n",
      "8.100982268401478e-05 2.104685720926553 6.708723068237305\n",
      "0.00022444436086192738 1.7799846127926064 7.242313385009766\n",
      "8.888426603388733e-05 3.5182602525517255 6.706035614013672\n",
      "0.0001224413663196776 1.6178374941189355 6.466038227081299\n",
      "0.00012340483143483388 1.580881847274734 6.517789363861084\n",
      "0.00017978318517118772 1.4345196970677132 6.627498149871826\n",
      "0.00011156853344547892 1.186419594644886 6.951559066772461\n",
      "0.00013738824134253147 1.2661631341941808 6.755532741546631\n",
      "0.00011865531063301295 1.7485181663326577 6.7021589279174805\n",
      "0.00014836005253101957 1.7489682200102281 6.863237380981445\n",
      "6.941253014345963e-05 2.192692141905094 6.7691874504089355\n",
      "8.316365793353368e-05 1.8696237985955362 7.022568702697754\n",
      "0.00019876781691315906 1.7905659492007928 6.844786643981934\n",
      "8.785509643724647e-05 1.387816807327893 7.099056243896484\n",
      "0.0004171951612144784 1.3380192335235028 6.857487201690674\n",
      "6.880591795103196e-05 1.5316210607755218 6.797640800476074\n",
      "7.570717220085859e-05 1.437314390722679 6.890025615692139\n",
      "0.00022945070878100006 1.7883861621846842 7.007801532745361\n",
      "0.0002205351638613881 1.741270571476441 6.80778694152832\n",
      "0.00010313523805760505 1.582337909087468 6.712526321411133\n",
      "7.009889684274238e-05 1.5197563206743703 6.804662227630615\n",
      "0.00010240078970381546 2.197367742340918 6.518791675567627\n",
      "0.00010501152505636606 1.3621284187277933 6.5597333908081055\n",
      "0.00024928960478776715 1.3976556034946561 7.005677223205566\n",
      "0.00017977817882984103 2.2489769037417466 6.853649139404297\n",
      "7.198604394502328e-05 2.2381493528393896 7.0042619705200195\n",
      "6.56420451901439e-05 1.346670339162012 6.593849182128906\n",
      "6.260930712731171e-05 1.417921885247861 6.740265369415283\n",
      "6.299548520685338e-05 1.5186866057381567 6.9886932373046875\n",
      "9.37864581216456e-05 1.2249114832009456 6.930450916290283\n",
      "7.430008656554366e-05 1.2483135699175603 6.614396095275879\n",
      "9.153822049005914e-05 1.4398578319743087 6.700962066650391\n",
      "0.00010334269533663801 1.3923042972146702 6.733933448791504\n",
      "7.560378569451038e-05 1.8034862031691379 6.636987209320068\n",
      "0.00010273598231066815 1.6934034743888553 6.67349100112915\n",
      "9.315114521616859e-05 1.194542704726304 6.5480265617370605\n",
      "8.041506785696056e-05 1.2463264722545495 6.723005294799805\n",
      "2.66920528883127e-05 1.7701437449371837 6.514775276184082\n",
      "0.00019673505672732468 1.1131455490224103 6.8384904861450195\n",
      "0.00014469914069267252 1.2991396544715847 6.5519561767578125\n",
      "0.00022866999183226907 1.998612543941441 6.529253005981445\n",
      "6.450446248742003e-05 1.4025230852188793 7.176176071166992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013830177517062755 1.7742978266125082 6.640829563140869\n",
      "0.00017562025796837624 1.3546848492600148 6.495552062988281\n",
      "7.745027929405603e-05 1.683356977393802 6.463523864746094\n",
      "8.041722864114908e-05 1.5709942767583172 6.708235263824463\n",
      "8.509464650451955e-05 2.0779902876365997 6.978182792663574\n",
      "6.305309287741474e-05 1.4590393037509306 6.896634101867676\n",
      "0.0001905756384047232 1.9012411025769866 6.588395118713379\n",
      "6.351431804534351e-05 1.8067135302384612 6.793454170227051\n",
      "7.677566794735645e-05 1.4138626283159372 6.811461448669434\n",
      "0.00011502792108024293 1.4741482679668556 6.496173858642578\n",
      "6.876097531786159e-05 1.092171212202331 6.8133625984191895\n",
      "0.00021309307103379986 1.9541082606133786 6.864954948425293\n",
      "0.00012779492316566398 1.353237043298314 6.533205509185791\n",
      "0.00013210139735011175 1.5333709794024115 6.736357688903809\n",
      "8.241344872619369e-05 1.30853159515686 6.965826511383057\n",
      "6.00032794554225e-05 1.4022543123308309 6.596604347229004\n",
      "5.758312175810071e-05 1.9403898575482694 6.7346415519714355\n",
      "9.474912049523022e-05 1.3625803011827757 6.917513847351074\n",
      "4.1585760582946765e-05 1.2643415441847559 6.815466403961182\n",
      "3.2132676120974864e-05 1.738196231593066 6.915040016174316\n",
      "6.43256730549607e-05 1.6039614434741747 6.670409679412842\n",
      "5.3791691291908876e-05 1.4539771331617735 6.190228462219238\n",
      "4.737862404541386e-05 2.395317509400513 6.617834091186523\n",
      "8.986461790768116e-05 2.423607298438812 7.0506391525268555\n",
      "0.00013431364970956992 2.8732418880748054 6.731316089630127\n",
      "0.0002650338748328879 2.2796053903014526 6.0486531257629395\n",
      "0.00029158642930555707 4.639500104065531 6.893684387207031\n",
      "5.859751561916818e-05 2.6530857476573377 6.657820701599121\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(25)):\n",
    "    for batch in data_loaders['train']:\n",
    "        optimizer.zero_grad()\n",
    "        logits = translation_model(batch)\n",
    "        loss = calc_loss(logits, batch['target'], criterion)\n",
    "        loss.backward()\n",
    "        \n",
    "        encoder_norm = 0\n",
    "        for p in translation_model.encoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            encoder_norm += param_norm.item() ** 2\n",
    "        decoder_norm = 0\n",
    "        for p in translation_model.decoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            decoder_norm += param_norm.item() ** 2\n",
    "            \n",
    "        print(encoder_norm, decoder_norm, loss.item())\n",
    "            \n",
    "        clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                                   translation_model.parameters()), 5.0)\n",
    "        \n",
    "        optimizer.step() \n",
    "    original, translation = evaluate(translation_model, data, data_loaders, dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024467507482357514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.greedy(x), data['train'])\n",
    "bleu_eval(original, translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023789236679995717"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.beam_search(x), data['train'])\n",
    "bleu_eval(original, translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "input_seq = x['input']\n",
    "target_seq = x['target']\n",
    "input_length = x['input_length']\n",
    "target_length = x['target_length']\n",
    "\n",
    "encoded_input, hidden = translation_model.encoder.forward(input_seq, input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6125, -0.5094,  0.1136,  ...,  0.2936, -0.0332, -0.5566],\n",
       "        [-0.2966, -0.5157,  0.0630,  ...,  0.6734,  0.0263, -0.9648],\n",
       "        [ 0.3257, -1.1140,  0.3586,  ...,  0.7310, -0.7097, -0.5748],\n",
       "        ...,\n",
       "        [-0.3053, -0.1229,  0.2143,  ..., -0.5936, -0.5418, -0.0655],\n",
       "        [-0.2868, -0.2641,  0.6324,  ..., -0.5235, -0.4746, -0.1487],\n",
       "        [-0.0230, -0.0655,  0.1169,  ..., -0.4210,  0.3063,  0.4462]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(9.9659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6769, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.0173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.1326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.8735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.7627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2807, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.0473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7510, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.7157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5111, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3349, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.7591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.5674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6708, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-2)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(x)\n",
    "    loss = calc_loss(logits, x['target'], criterion)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, data_loaders, dataset_type='dev', max_batches=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        original_strings = []\n",
    "        translated_strings = []\n",
    "        for i, batch in enumerate(data_loaders[dataset_type]):\n",
    "            if i > max_batches:\n",
    "                break\n",
    "            logits = translation_model(batch)\n",
    "            epoch_loss = calc_loss(logits, batch['target'], criterion)\n",
    "            original = output_to_translations(batch['target'], data['train'])\n",
    "            translations = output_to_translations(model.greedy(batch), data['train'])\n",
    "            original_strings.extend(original)\n",
    "            translated_strings.extend(translations)\n",
    "        bleu = bleu_eval(original_strings, translated_strings)\n",
    "        model.train()\n",
    "        print(epoch_loss)\n",
    "        print(bleu)\n",
    "        \n",
    "        return original_strings, translated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)\n",
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34410a3c73c44d89f2e6cddd5d165c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1389), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.1450, device='cuda:0')\n",
      "0.0008142795832761162\n",
      "tensor(9.0464, device='cuda:0')\n",
      "0.0033784249080402885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-bf6d2f87ea3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#evaluate(translation_model, data, data_loaders, dataset_type='train')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         decoder_outputs = Variable(torch.zeros(\n\u001b[0;32m--> 166\u001b[0;31m             model_config.max_length + 1, batch_size, self.decoder.output_size)).to(model_config.device)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm_notebook(data_loaders['train'])):\n",
    "    if i % 500 == 0:\n",
    "        evaluate(translation_model, data, data_loaders)\n",
    "        #evaluate(translation_model, data, data_loaders, dataset_type='train')\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(batch)\n",
    "    loss = calc_loss(logits, batch['target'], criterion)\n",
    "    loss.backward()\n",
    "    translation_model.encoder.embedding.weight.grad[data['train'].input_lang.pretrained_inds] = 0\n",
    "    translation_model.decoder.embedding.weight.grad[data['train'].output_lang.pretrained_inds] = 0\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strings, translated_strings = evaluate(translation_model, data, data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball be later but of volumes all. hope. answer. only were',\n",
       " 'be this. 65. know what must truth. i most',\n",
       " 'games be practical everybody pins your needles all forward careful were',\n",
       " 'i moment. it attack. be sorrows. ten.',\n",
       " 'canadian be appointment careful laugh. no truth. something time were',\n",
       " 'beautiful cupboard. hot. wine these',\n",
       " 'much. but how bitter really dishonesty fed recently',\n",
       " 'applied all else fed to climate husbands. matter. key',\n",
       " 'but they answer. perfect. today. tape',\n",
       " 'i is invented i situation getting powers your few']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = translation_model.greedy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in predictions.cpu().numpy():\n",
    "    decoded_words = []\n",
    "    for elem in row[1:]:\n",
    "        decoded_words.append(data['train']['output_lang'].index2word[elem])\n",
    "        if elem == model_config.EOS_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = Variable(torch.LongTensor([model_config.SOS_token] * 8)).to(model_config.device)\n",
    "yo = torch.stack((yo, topi.squeeze(), topi.squeeze()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = torch.autograd.Variable(torch.LongTensor(np.repeat([2], len(x['input_length'])))).to(model_config.device)\n",
    "mask = seq_range < x['input_length']\n",
    "loss = -torch.gather(decoder_output, dim=1, index=input_var.unsqueeze(1)).squeeze() * mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4193, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum() / torch.sum(loss > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(loss > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(x['input'], x['input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = None\n",
    "if decoder.attention:\n",
    "    context = Variable(torch.zeros(encoder_output.size(0), encoder_output.size(2))).unsqueeze(1).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, context, weights = decoder(input_var, encoder_hidden, encoder_output, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item() * \\\n",
    "            len(batch['label']) / len(train_loader.dataset)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30a2084915f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-df8527ea006d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(translation_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(translation_model, optimizer, train_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
