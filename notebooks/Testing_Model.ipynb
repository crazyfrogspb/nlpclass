{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from nlpclass.config import model_config\n",
    "from nlpclass.data.data_utils import TranslationDataset, text_collate_func\n",
    "from nlpclass.models.evaluation_utils import bleu_eval, output_to_translations\n",
    "from nlpclass.models.models import DecoderRNN, EncoderCNN, EncoderRNN, TranslationModel\n",
    "from nlpclass.models.training_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_DIR = osp.join(CURRENT_PATH, '..', 'data')\n",
    "MODEL_DIR = osp.join(CURRENT_PATH, '..','models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting words...\n",
      "Counted words:\n",
      "eng 27052\n",
      "vi 33338\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3562\n",
      "vi 3678\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3361\n",
      "vi 3518\n"
     ]
    }
   ],
   "source": [
    "data, data_loaders, max_length = load_data('vi', batch_size=24, subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderCNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2).to(model_config.device)\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=False).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(\n",
    "    data['train'].input_lang.n_words,\n",
    "    embedding_size=100,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.0,\n",
    "    bidirectional=True).to(model_config.device)\n",
    "if encoder.bidirectional:\n",
    "    multiplier = 2\n",
    "else:\n",
    "    multiplier = 1\n",
    "decoder = DecoderRNN(\n",
    "    embedding_size=100,\n",
    "    hidden_size=multiplier * 128,\n",
    "    output_size=data['train'].output_lang.n_words,\n",
    "    attention=True).to(model_config.device)\n",
    "translation_model = TranslationModel(encoder, decoder, teacher_forcing_ratio=0.5).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.ones(translation_model.decoder.output_size).to(model_config.device)\n",
    "weight[model_config.PAD_token] = 0\n",
    "criterion = nn.CrossEntropyLoss(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(logits, target, criterion):\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    target_flat = target.view(-1, 1).squeeze()\n",
    "    return criterion(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, data_loaders, dataset_type='dev', max_batch=100, greedy=True):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        original_strings = []\n",
    "        translated_strings = []\n",
    "        for i, batch in enumerate(data_loaders[dataset_type]):\n",
    "            if i > max_batch:\n",
    "                break\n",
    "            logits, loss = model(batch)\n",
    "            epoch_loss += loss.item()\n",
    "            original = output_to_translations(batch['target'], data['train'])\n",
    "            if greedy:\n",
    "                translations = output_to_translations(\n",
    "                    model.greedy(batch), data['train'])\n",
    "            else:\n",
    "                translations = output_to_translations(\n",
    "                    model.beam_search(batch), data['train'])\n",
    "            original_strings.extend(original)\n",
    "            translated_strings.extend(translations)\n",
    "        bleu = bleu_eval(original_strings, translated_strings)\n",
    "        model.train()\n",
    "\n",
    "    return epoch_loss / (i + 1), bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f20275ba14540ed8cac6f17d1f05972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.0760, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9517, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2301, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9269, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8331, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3624, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2147, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1306, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1396, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2075, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1114, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9482, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0504, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7690, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4243, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0681, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9339, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8612, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7834, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.5876, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.9310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1670, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0205, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3109, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.7567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7349, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2680, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2875, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2342, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9774, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9579, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9472, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0890, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3233, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0613, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7261, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3936, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0086, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4649, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2694, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8644, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0999, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4089, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.7189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3493, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7395, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1560, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3093, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8374, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0502, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1042, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7926, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.9547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2696, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5023, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9997, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3928, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.8189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6740, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.9458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9079, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1096, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9465, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8652, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0937, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4539, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1445, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0439, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9366, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2485, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3615, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2773, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3999, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1596, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0009, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7423, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3347, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5604, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3096, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.7170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0556, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9899, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.6201, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7014, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.6560, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.8294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4117, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.6079, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.9382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.3249, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.7270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9419, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1524, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0520, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9434, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0909, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2412, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6282, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.4937, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5444, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.7221, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.3420, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.6987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9181, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.6191, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.0999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5302, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.9091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4377, device='cuda:0', grad_fn=<MeanBackward1>) tensor(5.8466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0340, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8036, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9008, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0415, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5215, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.7943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8932, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0947, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.3908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.2536, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0721, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.8808, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.5531, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.5933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.4891, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0538, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.1142, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0720, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.2974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(5.9537, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.1940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(6.0029, device='cuda:0', grad_fn=<MeanBackward1>) tensor(6.4654, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7b2f492aa288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/nlp/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/PhD_Projects/nlpclass/nlpclass/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         decoder_outputs = Variable(torch.zeros(\n\u001b[0;32m--> 195\u001b[0;31m             model_config.max_length + 1, batch_size, self.decoder.output_size)).to(model_config.device)\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(25)):\n",
    "    for batch in data_loaders['train']:\n",
    "        translation_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        logits, total_loss = translation_model(batch)\n",
    "        loss = calc_loss(logits, batch['target'], criterion)\n",
    "        print(total_loss, loss)\n",
    "        total_loss.backward()\n",
    "        \n",
    "        encoder_norm = 0\n",
    "        for p in translation_model.encoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            encoder_norm += param_norm.item() ** 2\n",
    "        decoder_norm = 0\n",
    "        for p in translation_model.decoder.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            decoder_norm += param_norm.item() ** 2\n",
    "            \n",
    "        #print(encoder_norm, decoder_norm, loss.item())\n",
    "            \n",
    "        clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                                   translation_model.parameters()), 5.0)\n",
    "        \n",
    "        optimizer.step() \n",
    "    original, translation = evaluate(translation_model, data, data_loaders, dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0962950180861046\n",
      "[('but but but i was to the the the to the the the to the the the to the the the to the and the to the and the to the and the to the and the to the and the to the and the and the to the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and .', 'but the upshot of this is that the mission i want psychology to have in addition to its mission of curing the mentally ill and in addition to its mission of making miserable people less miserable is can psychology actually make people happier ?'), ('and you you to to the the the to the the the and we the the to the the the and the and the and the and .', 'see mr. hunter is doing that because he says his time has messed up a lot and hes trying to tell us how to fix that problem .'), ('and the the the the the the the the the the the the the the the the the the the the the the the the the the .', 'and in fact university administrators are a little uncomfortable about the idea that we may be getting close to 70 percent female population in universities .')]\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.greedy(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(list(zip(translations[0:3], original[0:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_model.beam_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0862594017124614\n",
      "[('but but but i was to the the to to the the to the the to the the to the the to the the to the the the to the and the to the and the to to the the the and and i was to the to the and the to the and the to the and the to the and the to the and the to the and the to the and the to the and the to the and the to the and the to the and the and .', 'but the upshot of this is that the mission i want psychology to have in addition to its mission of curing the mentally ill and in addition to its mission of making miserable people less miserable is can psychology actually make people happier ?'), ('and you you you to the to the to the to the to the to the to the the the and the and .', 'see mr. hunter is doing that because he says his time has messed up a lot and hes trying to tell us how to fix that problem .'), ('and the the the of the the the of the of the the the the the the the the the the .', 'and in fact university administrators are a little uncomfortable about the idea that we may be getting close to 70 percent female population in universities .')]\n"
     ]
    }
   ],
   "source": [
    "original = output_to_translations(x['target'], data['train'])\n",
    "translations = output_to_translations(translation_model.beam_search(x), data['train'])\n",
    "print(bleu_eval(original, translations))\n",
    "print(list(zip(translations[0:3], original[0:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.8092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(7.1293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.5016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.6025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.5010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.3718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.2512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.0624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.6674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.8056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.7100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.3998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.1066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.6685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.4467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.3085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.1397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0870, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9686, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.0618, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = next(iter(data_loaders['train']))\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-2)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    logits = translation_model(x)\n",
    "    loss = calc_loss(logits, x['target'], criterion)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, translation_model.parameters()), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92997d8a04cc4bc4b76b7089fd6baeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2778), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.087496595562628 0.00037814385791066975\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm_notebook(data_loaders['train'])):\n",
    "    if i % 300 == 0:\n",
    "        loss, bleu = evaluate(translation_model, data, data_loaders)\n",
    "        print(loss, bleu)\n",
    "        #evaluate(translation_model, data, data_loaders, dataset_type='train')\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = translation_model(batch)\n",
    "    loss.backward()\n",
    "    clip_grad_norm_(filter(lambda p: p.requires_grad,\n",
    "                               translation_model.parameters()), model_config.grad_norm)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strings, translated_strings = evaluate(translation_model, data, data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball be later but of volumes all. hope. answer. only were',\n",
       " 'be this. 65. know what must truth. i most',\n",
       " 'games be practical everybody pins your needles all forward careful were',\n",
       " 'i moment. it attack. be sorrows. ten.',\n",
       " 'canadian be appointment careful laugh. no truth. something time were',\n",
       " 'beautiful cupboard. hot. wine these',\n",
       " 'much. but how bitter really dishonesty fed recently',\n",
       " 'applied all else fed to climate husbands. matter. key',\n",
       " 'but they answer. perfect. today. tape',\n",
       " 'i is invented i situation getting powers your few']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the',\n",
       " 'i you you to the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_strings[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = translation_model.greedy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in predictions.cpu().numpy():\n",
    "    decoded_words = []\n",
    "    for elem in row[1:]:\n",
    "        decoded_words.append(data['train']['output_lang'].index2word[elem])\n",
    "        if elem == model_config.EOS_token:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = Variable(torch.LongTensor([model_config.SOS_token] * 8)).to(model_config.device)\n",
    "yo = torch.stack((yo, topi.squeeze(), topi.squeeze()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = torch.autograd.Variable(torch.LongTensor(np.repeat([2], len(x['input_length'])))).to(model_config.device)\n",
    "mask = seq_range < x['input_length']\n",
    "loss = -torch.gather(decoder_output, dim=1, index=input_var.unsqueeze(1)).squeeze() * mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4193, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum() / torch.sum(loss > 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(loss > 0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_hidden = encoder(x['input'], x['input_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = None\n",
    "if decoder.attention:\n",
    "    context = Variable(torch.zeros(encoder_output.size(0), encoder_output.size(2))).unsqueeze(1).to(model_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, context, weights = decoder(input_var, encoder_hidden, encoder_output, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = criterion(outputs, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item() * \\\n",
    "            len(batch['label']) / len(train_loader.dataset)\n",
    "    return loss_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30a2084915f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-df8527ea006d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, criterion)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(translation_model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_model(translation_model, optimizer, train_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
